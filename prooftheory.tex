\onehalfspacing

\chapter{Proof Theories and Logical Frameworks}

\section{Proof-theoretic type theory}

\subsection{Analytic and synthetic judgement}

A synthetic judgement is one for which the experience of \emph{coming
to know it} necessarily entails some knowledge which is not implicit
in the statement of the judgement; on the other hand, to know an
\emph{analytic} judgement is to know it purely on the basis of the
information contained inside it. So analytic judgements are decidable,
since if they may become evident, it will be purely on the basis of
their own content; whereas synthetic judgements become evident to
someone when they have obtained some particular evidence for them.

A logical theory has, then, both analytic and synthetic judgements;
the judgement $\isprop{P}$ is analytic, since its evidence follows
from the definition of $P$, whereas the assertion of $\istrue{P}$
entails the knowledge of some extra information, namely a verification
of $P$. When we have extended the logical theory to a type theory in
the manner of the previous chapter, the judgement $\ver{M}{P}$ is
also synthetic, since $\ver{M}{P}$ is not self-evident in general.

But why is it not enough to assert that $M$ verifies $P$ to know
whether $\ver{M}{P}$? It suffices to define a $P$ such that one cannot
decide in general whether some term is a verification of it. Let us
define the propositional symbol $\mathsf{P}$, and we intend to know
the judgement $\isprop{\mathsf{P}}$, whose meaning is to be expanded as
follows:
\begin{quote}
  To know $\isprop{\mathsf{P}}$ is to know counts as a canonical verification of $\mathsf{P}$.
\end{quote}

We will say, then, that $\bullet$ is a canonical verification of
$\mathsf{P}$ just when Goldbach's conjecture is true. Then it comes
immediately that the judgement $\ver{M}{\mathsf{P}}$ may not be known
or refuted on its own basis, nor even the judgement
$\ver{\bullet}{\mathsf{P}}$, since they depend on a proposition whose
truth is not known:

\begin{itemize}
  \item[] To know $\ver{M}{\mathsf{P}}$ is to know that $\reduce{M}{M'}$ to a
    canonical verification of $P$.
  \item[$\leadsto$] To know $\ver{M}{\mathsf{P}}$ is to know that
    $\reduce{M}{\bullet}$ such that Goldbach's conjecture is true.
\end{itemize}

\subsection{Proof of a judgement vs.\ verification of a proposition}

Because the judgement $\ver{M}{P}$ is synthetic, we cannot say that it
gives rise to a proof theory for the logic, since the core judgement
of a proof theory $\ofty{M}{A}$ must be analytic, in order to avoid the
infinite regress of a proof theory requiring a proof theory requiring
a proof theory, and so on.

The notion of verification of a proposition could never be the same as proof
anyway, except in the most trivial circumstances, since a verification is meant
to be an effective operation which realizes the truth of a proposition, and no
constraints whatsoever (termination, totality, etc.) are placed on these
operations except those which come from the meaning of the judgements (see
\cite{Dummett:Elements}, \cite{Prawitz12}, \cite{TroelstraA:conm}).

So a proof theory is necessarily intensional, and its judgements are to be
analytic/decidable. What is it, then, that we have considered so far which
corresponds with a proof $M$ such that $\ofty{M}{P}$ in a proof theory? As discussed
above, $M$ is not merely a term such that $\ver{M}{P}$, since this is not in
general enough information to know whether $M$ is a proof. In fact, $M$ must
comprise all the logical inferences which led to the knowledge that $P$ is
true, and so a meaning explanation for the judgement $\ofty{M}{P}$ in a proof theory
immediately suggests itself:
\begin{quote}
  To know $\ofty{M}{P}$ is to know that $M$ is evidence (demonstration, proof,
  derivation) of the judgement $\istrue{P}$.
\end{quote}

And so the term domain of the proof theory is not the same as the one that we
have considered so far; it must consist in terms which represent traces of the
inferences made in the course of knowing the judgements of a logical theory.
There is a sense in which one can consider the types of a proof theory to
interpret the judgements of the logical theory, and this methodology is called
``judgements as types'' (and this implies ``derivations as terms'').

What I am calling a ``proof-theoretic type theory'' is a type theory of the
sort used in the proof assistants Agda, Coq and Idris, whereas the kind of
type theory that I have described in the previous sections, the one based on
meaning explanations, underlies the proof assistant Nuprl.

The proof-theoretic type theories on the one hand are often called
``intensional'' and the computational type theories on the other hand are
usually ``extensional''; these characterizations are certainly true, though
they are not \emph{essential}; moreover, I fear that comparing one of the
former with one of the latter is not quite fair, since there is not any clear
analogy to be had. That is to say, the judgement $\ver{M}{P}$ is a judgement
which is added to a logical theory and its meaning is (briefly) ``$M$ evaluates
to a canonical verification of $P$'', whereas $\ofty{M}{P}$ cannot be construed
as a judgement added to a logical theory. Instead, it must be understood as
part of a (proof) theory which is overlayed atop an existing logical theory; it
is possible to understand the theory which contains the judgement $\ofty{M}{P}$
to be a metatheory, or logical framework, for the theory which contains the
judgement $\istrue{P}$, which can be construed as the ``object language''.

In short, the judgements $\ver{M}{P}$ and $\ofty{M}{P}$ are unrelated to each other in
two respects: firstly, that they have different meanings, and secondly that the
one is at the same level as the judgements of a logical theory, whereas the
latter is a judgement in a theory which is defined over a logical theory.

\section{Martin-L\"of's equational logical framework}

To make this more concrete, let us expound a proof theoretic type
theory called \MLLF, which stands for ``Martin-L\"of's (equational) logical
framework'';\footnote{For a detailed overview of Martin-L\"of's equational logical framework, see \cite{PiMLTT}.} in the course of introducing each type, we will specify
which judgement of the underlying logical theory it is meant to
interpret.

We start with four categorical judgements:\\

\begin{tabular}{c|l}
Judgement Form & Pronunciation \\ \hline
  $\type{\alpha}$ & $\alpha$ is a type \\
  $\etype{\alpha}{\beta}$ & $\alpha$ and $\beta$ are equal types \\
  $\ofty{M}{\alpha}$ & $M$ is of type $\alpha$ \\
  $\eofty{M}{N}{\alpha}$ & $M$ and $N$ are equal at type $\alpha$ \\
\end{tabular}\\

But we have not defined the meaning of the judgements; let us do so below:

\begin{quote}
  To know $\type\alpha$ is to know what counts as an object of type $\alpha$,
  and when two such objects are equal.
\end{quote}

For now, we'll leave the question of what is an ``object'' as
abstract; in many cases, types will represent judgements of a logical
theory, and the objects will be the derivations (demonstrations,
proofs) of those judgements.

\begin{quote}
  To know $\etype{\alpha}{\beta}$ is to know that any object of type $\alpha$ is
  also an object of type $\beta$, and two equal objects of type $\alpha$ are
  equal as objects of type $\beta$ (necessarily presupposing \type\alpha\ and
  \type\beta).
\end{quote}

\begin{quote}
  To know $\ofty{M}{\alpha}$ is to know that $M$ is an object of type $\alpha$
  (necessarily presupposing $\type\alpha$).
\end{quote}

\begin{quote}
  To know $\eofty{M}{N}{\alpha}$ is to know that $M$ and $N$ are equal objects of type
  $\alpha$ (necessarily presupposing $\ofty{M}{\alpha}$ and $\ofty{N}{\alpha}$).
\end{quote}

In addition to the above judgements, we will need contexts (with their
wellformedness judgement $\isctx{\Gamma}$) and an intensional sequent judgement
\framebox{$\lfsequent{\Gamma}{\mathcal{J}}$}; their meanings here will differ
from the sequent judgements of computational type theory, in that they must
mean proof-theoretic derivability, rather than semantic consequence.

At this point, we may begin adding types to the logical framework. In
practice, most types which we will introduce in the logical framework
will be defined in terms of a judgement of the logical theory which
lies below it.  For instance, hypothetical judgement in the logical
theory is represented by a function type in the logical framework,
$(x:\alpha)\beta$, whose typehood is meant to be evident under the
following circumstances
\[
  \infer{
    \type{(x:\alpha)\beta}
  }{
    \type\alpha &
    \lfsequent{x:\alpha}{\type\beta}
  }
\]
Or as a hypothetical judgement,
$\hyp{\type{(x:\alpha)\beta}}{\type\alpha,\lfsequent{x:\alpha}{\type\beta}}$.

Now, to know this judgement is to know that under the circumstances we
know what is an object of type $\alpha$ and when two such objects are
equal, and that if we have such an object $x$ of type $\alpha$, we
know what an object of type $\beta$ is, and when two such objects are
equal---then we know what an object of type $(x:\alpha)\beta$ is, and
moreover, for any two objects $y,z$ of type $\alpha$, that
$[y/x]\beta$ and $[z/x]\beta$ are equal as types. To make this
evident, then, we will say that under those circumstances an object of
type $(x:\alpha)\beta$ is an object $[x]M$ such that one knows
$\lfsequent{x:\alpha}{\ofty{M}{\beta}}$ and $\genj{x,y}{\hyp{\eofty{[y/x]M}{[z/x]M}{[y/x]\beta}}{\eofty{y}{z}{\alpha}}}$;
furthermore, two such objects are equal just when they yield equal
outputs for equal inputs.

Then, for each atomic proposition $P$, we can easily
define a type $\prf{P}$, as follows. Under the circumstances that
$\isprop{P}$ in the logical theory, then $\type{\prf{P}}$ in the
logical framework, since we will define an object of type $\prf{P}$ to
be a derivation of $\istrue{P}$; beyond reflexivity,
further definitional equalities can be added to reflect the harmony of
introduction and elimination rules.

Now, the definitions we have given for the types above are
``intuitively'' correct, but they actually fail to satisfy the meaning
explanation that we have given for $\type\alpha$, because they do not
take into account neutral terms. In the following sections, we will
investigate this problem in more detail and propose a solution.

\subsection{What is an ``object''?}
It is time to revisit what it means to be an ``object'' of a type in the
proof-theoretic type theory; we must note how this will necessarily differ from
what it meant to be a ``verification'' of a proposition in the previous
sections. Namely, a verification of a proposition is either a \emph{canonical
verification} of that proposition (and what sort of thing this might be is
known from the presupposition $\isprop{P}$), or it is a means of getting such
a canonical verification (i.e. a term which evaluates to a canonical
verification).

On the other hand, what we have called an ``object'' of type $P$ is quite
different, since in addition to the possibility that it is a canonical proof of
the judgement $\istrue{P}$, it may also be \emph{neutral} (i.e. blocked by a
variable); we will call this ``normal'' rather than ``canonical''. Why does
this happen?

In order to keep the judgement $\ofty{M}{A}$ analytic (decidable), its meaning
explanation can no longer be based on the idea of the computation of closed
terms to canonical form; instead, we will consider the computation of open
terms (i.e. terms with free variables) to \emph{normal} form. The desire for
$\ofty{M}{A}$ to be analytic follows from our intention that it characterize a
\emph{proof theory}: we must be able to recognize a proof when we see one. But
why are closed-term-based meaning explanations incompatible with this goal?
Consider briefly the following judgement:
\[
  \genj{n}{\hyp{\ver{M(n)}{P}}{\ver{n}{\naturals}}}
\]

To know this judgement is to know that $M(n)$ computes to a canonical
verification of $P$ whenever $n$ is a natural number; when $P$'s use of $n$ is
not trivial, this amounts to testing an infinite domain (all of the natural
numbers), probably by means of mathematical induction. The judgement is then
clearly synthetic: to know it is, briefly, to have come up with an (inductive)
argument that $M(N)$ computes to a canonical verification of $P$ at each
natural number $n$.

On the other hand, the judgement $\lfsequent{n:\naturals}{\ofty{M(n)}{P}}$ must have a
different meaning, one which admits its evidence or refutation purely on
syntactic/analytic grounds. In essence, it is to know that $M(n)$ is a proof of
$P$ for any \emph{arbitrary} object/expression $n$ such that $\ofty{n}{\naturals}$
(i.e., the only thing we know about $n$ is that it is of type $\naturals$; we
do not necessarily know that it is a numeral).


\section{A critique of \textbf{MLLF}}

The type theory which we constructed in the previous section is to be
considered a proof theory for a logic with the judgements
$\isprop{P}$, $\istrue{P}$ and
$\hyp{\mathcal{J}}{\mathcal{J}'}$. There are a few reasons to be
dissatisfied with this state of affairs, which I shall enumerate in
this section.

\subsection{Lack of computational content}

Unlike the type theory in the first chapter, there is no built-in computational
content. In a computational type theory which is defined by the verificationist
meaning explanations, the computational content of terms is understood
immediately by means of the $\reduce{M}{M'}$ relation; that is, computation is
prior to the main judgements because their meaning explanations are defined in
terms of evaluation to canonical form.

On the other hand, in the type theory above we did not give a
primitive reduction relation; instead, we simply permitted the
endowement of proofs with definitional equalities which reflect the
harmony of introduction and elimination rules. That is, if we have
known the judgement $\istrue{P}$ by means of an indirect argument
(derivation), it must be the case that this derivation corresponds to
a direct one; we reflect this in the proof theory by defining the
indirect derivation to be definitionally equal to the direct one.

However, this does not amount to computational content being present in terms:
only \emph{post facto} may the definitional equality be construed as giving
rise to computation, through a metamathematical argument which shows that the
definitional equality is confluent and can be used to define a functional
normalization relation.

And this is the reason for the peculiarity of the proof-theoretic
meaning explanations, namely that they do not include phrases like
``evaluates to a canonical...'', since evaluation may only be
understood after taking the meanings of the judgements ($\type\alpha$,
$\etype{\alpha}{\beta}$, $\ofty{M}{\alpha}$, $\eofty{M}{N}{\alpha}$) as giving rise to a
closed formal system which is susceptible to metamathematical
argument: to refer to evaluation in the meaning explanations for the
core judgements, then, would be impredicative.

\subsection{Modularity of definition}

By the same token, the distinction between canonical (direct) and non-canonical
(indirect) proof may not be understood as a core notion in the theory, but must
be understood separately, secondarily. Why is this a problem? It means that the
definition of each type must be made with the full knowledge of the definitions
of every other type; in essence, the open-ended nature of type theory is
obliterated and one is forced into a fixed formal system; this is in addition
to the fact that it causes the epistemic content of $\type\alpha$ for any type
$\alpha$ to be extremely complicated.

To illustrate, let us consider as an example a type theory which has
four type-formers: trivial truth $\top$, trivial falsity $\bot$,
implication $(\alpha)\beta$, and conjunction $\product\alpha\beta$; we
will then introduce the following terms to represent proofs: the
trivial element $\bullet$, \emph{reductio ad absurdum}
$\abort{\alpha}{E}$, abstraction $[x:\alpha]E$, application $E(E')$,
pairing $\pair{E}{E'}$, and projections $\fst{E}$, $\snd{E}$.

If we will try to make the judgement $\type\top$ evident, the deficiencies of
the formulation will immediately present themselves.

\begin{quote}
To know $\type\top$ is to know what counts as an object of type $\top$, and when
two such objects are equal. An object of type $\top$, then, is either the
expression $\bullet$, or an expression $\abort{\top}{E}$ such that we know
$\ofty{E}{\bot}$, or an expression $E(E')$ such that we know $\ofty{E}{(\alpha)\top}$ and
$\ofty{E'}{\alpha}$, or an expression $\fst{E}$ such that we know $\ofty{E}{\product\top\beta}$
for some $\beta$, or an expression $\snd{E}$ such that we know
$\ofty{E}{\product\alpha\top}$ for some $\alpha$; and we additionally have that $\bullet$
is equal to $\bullet$, and ...
\end{quote}

To save space, we elide the rest of the definition of equality for $\top$; what
we have seen so far already suffices to bring to light a serious problem: the
definition of any type requires knowledge of the entire syntax of the theory.
The judgement $\type\alpha$ may never be made evident in isolation, but must be
done with full understanding of all the other types and their definitions.

Furthermore, to extend an existing theory with a new type, the definitions of
every other type must be rewritten to account for the elimination forms of the
new type.

\section{A way forward: verifications \& uses}

The second critique of \MLLF{} may be partially addressed by fragmenting type
theory into a logic of \emph{verifications \& uses}: instead of a type being
defined by its introduction rules, it must be simultaneously defined by its
introduction rules (verifications) and its elimination rules (uses). In
practice, this amounts to a standard technique known as \emph{bidirectional
type checking}.

The semantic priority of the forms of judgement also changes drastically: the
sequent judgement must in this case be explained \emph{before} the categorical
judgements; moreover, sequents may no longer be explained modularly in terms of
general and hypothetical judgement, since the latter amounts to
\emph{semantic} consequence (admissibility), whereas the meaning of a sequent
in a proof theory should be \emph{syntactic} consequence (derivability).

Because the target theory lacks computation, it is necessary to rule out
redexes from terms syntactically, but this complicates the definition of
substitution; to address this, Watkins introduced in \cite{watkins} a technique
known as \emph{hereditary substitution}, which is a family of syntax-directed
(algorithmic) judgements which contract redexes along the way, guaranteeing
canonical form in their outputs. Both bidirectional type checking and
hereditary substitutions have been used to great effect in the descendants of
the Edinburgh Logical Framework (see \cite{Harper-Licata-2007}).

The first critique, the lack of computational content, is more difficult to
address. Roughly, the right way to do it is to replace the notion of the
evaluation of closed terms to canonical form with the evaluation of \emph{open}
terms to normal form. Peter Dybjer demonstrates in \cite{series/leus/Dybjer12a}
how this technique may be used to endow the Calculus of Constructions with a
meaning explanation, albeit necessarily of a very different kind than we have
considered here.

%% \section{A modular logical framework via verifications \& uses}
%%
%% We will first try and address the easier of the two critiques by
%% factoring the judgements of the logical framework in such a way as to
%% permit different types to be defined modularly in isolation, and then
%% composed freely into theories. In order to simplify matters, we will
%% restrict our syntax to normal forms, thus eliminating the need for a
%% judgemental equality any more advanced than simple
%% $\alpha$-equivalence.
%%
%% The source of the anti-modularity in the previous section's
%% presentation was the fact that the introduction of a type and the
%% elimination of a type were considered within the same judgement. A
%% simple way to resolve this issue is to separate the typing judgement
%% $\ofty{M}{A}$ into two separate judgements, a checking judgement
%% $\checks{M}{A}$ and a synthesizing judgement
%% $\infers{R}{A}$; the basic idea is that introduction forms
%% (``verifications'') are to be checked, and elimination forms
%% (``uses'') are to be synthesized (or inferred). \textbf{Note that in this
%% chapter, we have no further use for the big-step reduction judgement
%% $\reduce{M}{M'}$; since there will be no ambiguity, so we will re-use
%% its notation for the type synthesis judgement.}
%%
%% In fact, the technique described above is commonplace in practical
%% implementations of type theory for proof assistants. In practice,
%% checkable terms and inferrable terms are usually put into separate
%% syntactic categories as well; because we need our syntax, judgements
%% and definitions to be as modular as possible, we will find even
%% further granularity to be useful.
%%
%% \subsection{Syntax and judgements}
%%
%% We introduce several syntactic categories (sorts):\\
%%
%% \begin{tabular}{lll}
%%   \toprule
%%   sort & names & description\\ \midrule
%%   $\mathbf{ctx}$ & $\Gamma, \Delta$ & contexts\\
%%   $\val$ & $M, N, \alpha, \beta$ & values (canonical forms and types) \\
%%   $\utm$ & $U, V$ & uses (eliminators) \\
%%   $\rtm$ & $R, S$ & neutral terms (variables and applied uses) \\
%%   $\mtm$ & $E,F,A,B$ & expressions (normal forms, i.e.\ canonical forms, neutral terms)\\
%%   \bottomrule
%% \end{tabular}\\
%%
%% A \emph{value} is an introduction form, like $\pair{E_1}{E_2}$ or
%% $[x]E$. A \emph{use} is an unapplied elimination form, like $\ufst$,
%% $\usnd$, or $\uap{N}$. A \emph{neutral term} is a variable $x$, or it
%% is an application $\elim{U}{R}$ of a use $U$ to a neutral term $R$,
%% like $\elim{\ufst}{R}$. Lastly, an \emph{expression} is a value $\ival{M}$ or it
%% is a neutral term $\ineu{R}$.
%%
%% Then, we will have the following forms of judgement, each of which
%% will be given a meaning explanation:\\
%%
%% \begin{tabular}{ll}
%%   \toprule
%%   judgement & pronunciation\\ \midrule
%%   $\lfctx{\Gamma}$ & ``$\Gamma$ is a context''\\
%%   $\fresh{x}{\Gamma}$ & ``$x$ is fresh in $\Gamma$''\\
%%   $\hasvar{\Gamma}{x}{A}$ & ``$\Gamma$ contains $x:A$''\\
%%   $\lfsequent\Gamma\cantype{\alpha}$ & ``$\alpha$ is a canonical type in context $\Gamma$''\\
%%   $\lfsequent\Gamma\type{A}$ & ``$A$ is a type in context $\Gamma$''\\
%%   $\lfsequent\Gamma\valof{M}{\alpha}$ & ``$M$ is a canonical verification of $A$ in context $\Gamma$''\\
%%   $\lfsequent\Gamma\useof{U}{\alpha}{x}{B(x)}$ & ``$U$ is a use of $x:\alpha$ yielding $B(x)$ in context $\Gamma$''\\
%%   $\lfsequent\Gamma\infers{R}{A}$ & ``$R$ synthesizes type $A$ in context $\Gamma$''\\
%%   $\lfsequent\Gamma\checks{E}{A}$ & ``$E$ checks at type $A$ in context $\Gamma$''\\
%%   $\eapply{U}{M}{E}$ & ``$U$ applied to $M$ yields $E$\\
%%   $\hsubste{E}{x}{M}{M'}$ & ``the substitution of $E$ for $x$ in $M$ is $M'$\\
%%   $\hsubstu{E}{x}{U}{U'}$ & ``the substitution of $E$ for $x$ in $U$ is $U'$\\
%%   $\hsubste{E}{x}{F}{F'}$ & ``the substitution of $E$ for $x$ in $F$ is $F'$\\
%%   $\hsubstr{E}{x}{R}{R'}$ & ``the substitution of $E$ for $x$ in $R$ is $R'$\\
%%   $\hsubstrm{E}{x}{R}{E'}$ & ``the substitution of $E$ for $x$ in $R$ is $E'$\\
%%   \bottomrule
%% \end{tabular}\\
%%
%% Note that we have made many of the above judgements with respect to a
%% context. It is tempting to first define the each judgement
%% ``categorically'' (i.e. without a context), and it is often done this
%% way in presentations of type theory,
%% but this is not actually possible for an intensional type theory, where the
%% meaning of the sequent judgement is not compositional. In fact, the
%% sequent judgement for intensional type theories may not even be
%% defined in terms of Martin-L\"of's hypothetical judgement, since the
%% former represents derivability, whereas the latter encompasses
%% admissibility as well. In this sense, then, even the sequent
%% judgements above are ``categorical''.
%%
%% \subsection{Meaning explanations}
%%
%% For each form of judgement listed in the previous section, a meaning
%% explanation will be given.
%%
%% \begin{quote}
%%   To know $\lfctx\Gamma$ is to know that $\match{\Gamma}{\cdot}$; or it is
%% to know that $\match{\Gamma}{\Delta,x:A}$ such that $\lfctx\Delta$, $\fresh{x}{\Delta}$ and
%% $\lfsequent\Delta\type{A}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\fresh{x}{\Gamma}$ is to know that $\match\Gamma\cdot$, or
%% to know a context $\Delta$ and a variable $\fresh{y}{\Delta}$ such
%% that $x$ is not $y$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hasvar{\Gamma}{x}{A}$ (presupposing $\lfctx\Gamma$) is to
%% know that $\match{\Gamma}{\Delta,x:A}$, or to know that
%% $\match{\Gamma}{\Delta, y:A}$ such that $\hasvar{\Delta}{x}{A}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\cantype{\alpha}$ (presupposing $\lfctx\Gamma$) is
%% to know what counts as a canonical verification of $\alpha$ in context
%% $\Gamma$, and what is a use of $x:\alpha$ yielding what in context
%% $\Gamma$; moreover, for any such use $U$ and any such canonical
%% verification $M$, to know what expression is yielded by applying $U$
%% to $M$. Moreover, for any such verification $M$ and any variable $x$,
%% to know the value of the substitution of $E$ for $x$ in $M$ for any
%% $E$; and for any such use $U$ and any variable $x$, to know the
%% substitution of $E$ for $x$ in $U$ for any $E$; finally, to know the
%% substitution of $E$ for $x$ in $\alpha$ for any $E$ and $x$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\type{A}$ is to know a type $\alpha$ such that $\match{A}{\ival{\alpha}}$ and $\lfsequent\Gamma\cantype\alpha$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\valof{M}{\alpha}$ (presupposing
%% $\lfsequent\Gamma\cantype{\alpha}$) is to know that $M$ is a canonical
%% verification of $\alpha$ in context $\Gamma$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\useof{U}{\alpha}{x}{B(x)}$ (presupposing
%% $\lfsequent\Gamma\cantype{\alpha}$, $\lfsequent{\Gamma,x:\ival\alpha}{\type{B(x)}}$ and
%% $\fresh{x}{\Gamma}$) is to know that $U$ is a use of $x:\alpha$ yielding
%% $B(x)$ in context $\Gamma$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\infers{R}{A}$ (presupposing
%% $\lfctx\Gamma$) is, if $\match{R}{x}$, to know that
%% $\hasvar{\Gamma}{x}{A}$; if $\match{R}{\elim{U}{S}}$, then it is to
%% know that $\lfsequent\Gamma\useof{U}{\beta}{x}{C(x)}$,
%% $\lfsequent\Gamma\infers{S}{\ival\beta}$, and $\match{C(\elim{U}{S})}{A}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\lfsequent\Gamma\checks{E}{A}$ (presupposing
%% $\lfsequent\Gamma\type{A}$) is, if $\match{E}{\ineu{R}}$, to know that
%% $\lfsequent\Gamma\infers{R}{A}$; if $\match{E}{\ival{M}}$, then it is to know
%% $\match{A}{\ival\alpha}$ and $\lfsequent\Gamma\valof{M}{\alpha}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\eapply{U}{M}{E}$ is to know that $U$ applied
%% to $M$ yields $E$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hsubste{E}{x}{M}{M'}$ is to know that the substitution of $E$ for $x$ in $M$ is $M'$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hsubste{E}{x}{U}{U'}$ is to know that the substitution of $E$ for $x$ in $U$ is $U'$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hsubste{E}{x}{\ineu{R}}{\ineu{R'}}$ is to know that
%% $\hsubstr{E}{x}{R}{R'}$; to know $\hsubste{E}{x}{\ineu{R}}{\ival{M}}$
%% is to know that $\hsubstrm{E}{x}{R}{\ival{M}}$; to know
%% $\hsubste{E}{x}{\ival{M}}{\ival{M'}}$ is to know that
%% $\hsubstm{E}{x}{M}{M'}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hsubstr{E}{x}{R}{R}$ is to know that $x$ does not occur
%% free in $R$; to know $\hsubstr{E}{x}{\elim{U}{R}}{\elim{V}{S}}$ is to
%% know that $\hsubstu{E}{x}{U}{V}$ and $\hsubstr{E}{x}{R}{S}$.
%% \end{quote}\medskip
%%
%% \begin{quote}
%%   To know $\hsubstrm{E}{x}{x}{E}$ is immediate; to know
%% $\hsubstrm{E}{x}{\elim{U}{R}}{E'}$ is to know that
%% $\hsubstu{E}{x}{U}{V}$, $\hsubstrm{E}{x}{R}{F}$, and $\eapply{V}{F}{E'}$.
%% \end{quote}\medskip
%%
%% Many of the above explanations may be given more clearly as inference
%% rules; it is not some peculiarity of meaning explanations that they
%% must be given in prose rather than mathematical notation, though we
%% have stuck to the former here for uniformity.
%%
%% \subsubsection{Discussion}
%%
%% The idea of separating out unapplied elimination forms (\emph{uses} in
%% our parlance) is closely related to the notion of \emph{spines}, which
%% are lists of \emph{uses}, which may be applied all at once to
%% a variable. It would be possible to add further syntax and judgements
%% for spines into our system, but the primary reason for separating out
%% the \emph{uses} in the first place was simply to make the evidence for
%% $\lfsequent\Gamma\cantype{\alpha}$ as minimal as possible, so as to make the
%% definitions of the types both economical and modular.
%%
%% The substitution judgements that we gave over each relevant syntactic category
%% give rise to a system of \emph{hereditary substitution} (see \cite{watkins});
%% the purpose of hereditary substitutions is to provide a way to substitute a
%% normal form into a term without creating redexes. The hereditary substitutions
%% may be divided into two groups. First, the structural substitutions which must
%% be given separately for the operators of each type, $\hsubstm{E}{x}{M}{M'}$ and
%% $\hsubstr{E}{x}{U}{U'}$; these may be implemented mechanically, by induction on
%% the arity of each operator. Second, the substitutions which may be implemented
%% once and for all in terms of the other judgements, namely
%% $\hsubstrm{E}{x}{R}{M}$, $\hsubstr{E}{x}{R}{S}$ and $\hsubste{E}{x}{F}{F'}$.
%%
%% Lastly, in its full presentation, Martin-L\"of's logical framework has
%% a single universe $\mathsf{Set}$ such that
%% $\hyp{\type{\mathsf{El}(A)}}{\ofty{A}{\mathsf{Set}}}$; in a proper
%% development of our modular logical framework, we would need to add
%% such a universe. In order to do this, the meaning explanation of
%% $\lfsequent\Gamma\type{A}$ (which is defined trivially in terms of
%% $\lfsequent\Gamma\cantype\alpha$) would have to be adjusted, in order
%% to take into account the neutral types which would be introduced by
%% the universe.
%%
%% \subsection{The definitions of types}
%%
%% Now we will proceed with defining some basic types according to the
%% meaning explanations we gave above.
%%
%% \subsubsection{The unit type}
%%
%% The following operators are introduced with their sorts:
%% \begin{gather*}
%%   \tyunit : \val\qquad \bullet : \val
%% \end{gather*}
%%
%% Then, we will make the judgement
%% $\genj{\Gamma}{\lfsequent\Gamma\cantype\tyunit}$ evident; note that we will use
%% Martin-L\"of's general judgement in order to express that the typehood
%% assertion is valid in \emph{any} context. The evidence of this
%% judgement is the following list of definitions:
%% \begin{enumerate}
%%   \item $\bullet$ is a canonical verification of $\tyunit$ in context $\Gamma$.
%%   \item There are no applicable uses.
%%   \item For any $E$ and $x$, the substitution of $E$ for $x$ in $\bullet$ is $\bullet$.
%%   \item For any $E$ and $x$, the substitution of $E$ for $x$ in $\tyunit$ is $\tyunit$.
%% \end{enumerate}
%%
%% \subsubsection{The empty type}
%% For the empty type, we introduce the following operators:
%% \begin{gather*}
%%   \tyvoid:\val \qquad \hyp{\uabort{A}:\utm}{A:\mtm}
%% \end{gather*}
%%
%% The judgement $\genj{\Gamma}{\lfsequent\Gamma\cantype\tyvoid}$ is made
%% evident by means of the following definitions:
%% \begin{enumerate}
%%   \item There is no canonical verification of $\tyvoid$.
%%   \item $\uabort{A}$ is a use of $x:\tyvoid$ yielding $A$ in context $\Gamma$, assuming $\lfsequent\Gamma\type{A}$.
%%   \item For any $E$ and $x$, the substitution of $E$ for $x$ in $\uabort{A}$ is $\uabort{A'}$, assuming $\hsubste{E}{x}{A}{A'}$.
%%   \item For any $E$ and $x$, the substitution of $E$ for $x$ in $\tyvoid$ is $\tyvoid$.
%% \end{enumerate}
%%
%% This is the first time we have seen a significant difference in
%% practice from the extensional type theory explored in the previous
%% chapter; note how we include an elimination form for $\tyvoid$ in its
%% definition, whereas in extensional type theory this is entirely
%% unnecessary.
%%
%% \subsubsection{The dependent function type}
%% For the dependent function type, the following operators are introduced:
%% \begin{gather*}
%%   \hyp{(x:A)B(x) : \val}{A:\mtm, \hyp{B(x):\mtm}{x:\rtm}}\\
%%   \hyp{[x]E(x) : \val}{\hyp{E(x):\mtm}{x:\rtm}}\\
%%   \hyp{\uap{E}:\utm}{E:\mtm}
%% \end{gather*}
%%
%% The judgement
%% $\genj{\Gamma}{%
%%   \hyp{%
%%     \lfsequent\Gamma{
%%       \cantype{(x:A)B(x)}%
%%     }
%%   }{%
%%     \lfsequent\Gamma{\type{A}};\ %
%%     \lfsequent{\Gamma,x:A}{\type{B(x)}}
%%   }%
%% }$
%% is made evident via the following definitions:
%% \begin{enumerate}
%%   \item A canonical verification of $(x:A)B(x)$ in context $\Gamma$ is
%% $[x]E(x)$, such that $\lfsequent{\Gamma,x:A}{\checks{E(x)}{B(x)}}$
%%   \item $\uap{E}$ is a use of $z:(x:A)B(x)$ yielding $B'$ in context $\Gamma$, assuming $\lfsequent\Gamma\checks{E}{A}$ and $\hsubste{E}{x}{B}{B'}$.
%%   \item Applying $\uap{E}$ to $[x]F(x)$ yields $F'$, assuming $\hsubste{E}{x}{F}{F'}$.
%%   \item The substitution of $E$ for $z$ in $[x]F(x)$ is $[x]F'(x)$, assuming $\hsubste{E}{z}{F}{F'}$.
%%   \item The substitution of $E$ for $z$ in $\uap{F}$ is $\uap{F'}$, assuming $\hsubste{E}{z}{F}{F'}$.
%%   \item The substitution of $E$ for $z$ in $(x:A)B(x)$ is $(x:A')B'(x)$, assuming $\hsubste{E}{z}{A}{A'}$ and $\hsubste{E}{z}{B}{B'}$.
%% \end{enumerate}
%%
%% Based on this definition, and the meanings of the judgements, the
%% familiar inference rules are valid (justified):
%% \begin{gather*}
%%   \infer{
%%     \lfsequent\Gamma\type{\ival{(x:A)B(x)}}
%%   }{
%%     \lfsequent\Gamma\type{A} &
%%     \lfsequent{\Gamma,x:A}\type{B(x)}
%%   }\\[6pt]
%%   %
%%   \infer{
%%     \lfsequent\Gamma\checks{\ival{[x]E(x)}}{\ival{(x:A)B(x)}}
%%   }{
%%     \lfsequent{\Gamma,x:A}\checks{E(x)}{B(x)}
%%   }
%%   \qquad
%%   \infer{
%%     \lfsequent\Gamma\infers{\elim{\uap{E}}{F}}{B'}
%%   }{
%%     \lfsequent\Gamma\infers{F}{\ival{(x:A)B(x)}} &
%%     \hsubste{E}{x}{B}{B'}
%%   }
%% \end{gather*}
%%
%% I leave the proofs of the validity of these rule schemes as an
%% exercise to the reader.
%%
%% \subsection{Discussion}
%%
%% In this chapter, a logical framework has been developed which, unlike
%% Martin-L\"of's logical framework, permits the modular/separate
%% definitions of types. On the other hand, we have \emph{not} addressed
%% the first critique of \MLLF, which is that it lacks computational
%% content.
%%
%% To make the framework truly computational, it would be necessary to
%% modify the syntax to include redexes, add judgements for reduction of
%% open terms to normal form (as opposed to reduction of closed terms to
%% canonical form), and adjust the meaning explanations of the judgements
%% $\lfsequent\Gamma\checks{M}{A}$ and $\lfsequent\Gamma\infers{R}{A}$ to
%% normalize their subjects.
%%
